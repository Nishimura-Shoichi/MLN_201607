{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 「深層学習」読書会　〜第7章〜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-size:150%;line-height:150%\">2016/07/02 機械学習 名古屋 第5回勉強会</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 第7章 再帰型ニューラルネット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "abstract:\n",
    "\n",
    "+ RNN（再帰型ニューラルネットワーク）\n",
    "    + 以下のようなデータの特徴をうまく取り扱うNN：\n",
    "        + データの長さがサンプルごとにまちまち\n",
    "        + 系列内の要素の並び（＝コンテキスト）に意味がある\n",
    "    + 例：音声・言語・動画\n",
    "+ LSTM（長・短期記憶）\n",
    "    + より長期のコンテキストをモデル化可能\n",
    "+ CTC（コネクショニスト時系列分類法）\n",
    "    + 入力系列とは長さの異なる系列を推定（出力）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7.1 系列データの分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**系列データ**：\n",
    "\n",
    "+ 個々の要素の順序付き集まりデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\bf x}^1, {\\bf x}^2, {\\bf x}^3, \\dots , {\\bf x}^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "+ 音声・動画・テキストなど\n",
    "+ 系列の長さ $T$ は、一般に可変\n",
    "+ インデックス $t = 1, 2, 3, \\dots$ を **時刻**と呼ぶ（*時間*とは言ってない）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**RNN（再帰型ニューラルネット）**：\n",
    "コンテキストを学習し、分類出来る。\n",
    "\n",
    "**コンテキスト（文脈）**：系列内の要素の並び、依存関係\n",
    "\n",
    "要素の例：\n",
    "\n",
    "+ 文章中の「単語」\n",
    "+ 音声信号中の「音素」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7.2 RNNの構造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN（再帰型ニューラルネット）**：\n",
    "\n",
    "+ 内部に（有向）閉路を持つNNの総称\n",
    "+ 特徴：\n",
    "    + 情報を一時的に記憶\n",
    "    + 振る舞いを動的に変化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# fig_7_3_a = Digraph(\"fig_7_3_a\", format=\"svg\")\n",
    "# 《編集中》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# fig_7_3_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# fig_7_3_b = Digraph(\"fig_7_3_b\", format=\"svg\")\n",
    "# 《編集中》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# fig_7_3_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# fig_7_4 = Digraph(\"fig_7_4\", format=\"svg\")\n",
    "# 《編集中》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# fig_7_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "誤差関数：（順伝播ネットワークと同様）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E({\\bf w}) = - \\sum_n \\sum_t \\sum_k d^t_{nk} \\log y^t_k({\\bf x}_n; {\\bf w})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし $d^t_n$：$n$ 番目のサンプル ${\\bf x}_n$ に対する、時刻 $t$ での目標出力  \n",
    "（$(d^t_{n1}, d^t_{n2}, \\dots , d^t_{nk})$ というベクトル）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**双方向RNN**：  \n",
    "データを 順方向 逆方向 両方の入力で与えるRNNを統合したもの。\n",
    "\n",
    "+ データの数が有限ならば有効\n",
    "+ オンライン学習には不向き"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7.3 順伝播計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《略》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7.4 逆伝播計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《略》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7.5 長・短期記憶（LSTM）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 7.5.1 RNN の勾配消失問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 7.5.2 LSTM の概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 7.5.3 順伝播計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 7.5.4 逆伝播計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7.6 入出力間で系列長が異なる場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 7.6.1 隠れマルコフモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 7.6.2 コネクショニスト時系列分類法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "《略》"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "TensorFlow v0.8 (Python 3)",
   "language": "python",
   "name": "tensorflow08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
